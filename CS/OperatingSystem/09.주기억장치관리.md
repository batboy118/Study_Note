# 09. 주기억장치 관리

> 메모리는 CPU만큼 컴퓨터를 사용하는데 매우 중요한 자원이다. 지금 까지 CPU 관리에 대해서 학습 했다면, 지금 부터는 메모리 관리에 대해서 살펴보자.

[🏠Home](https://github.com/batboy118/Study_Note)

[◀Previous page ](./README.md)

---

<!-- TOC -->

- [1. 메모리 역사](#1-메모리-역사)
- [2. 프로그램을 메모리에 올리기](#2-프로그램을-메모리에-올리기)
- [3. 메모리 낭비 방지](#3-메모리-낭비-방지)
	- [3.1. 동적 적재 (Dynamic Loading)](#31-동적-적재-dynamic-loading)
	- [3.2. 동적 연결 (Dynamic Linking)](#32-동적-연결-dynamic-linking)
	- [3.3. Swapping](#33-swapping)
- [4. 연속 메모리 할당 (Contiguous Memory Allocation)](#4-연속-메모리-할당-contiguous-memory-allocation)
	- [3.1. 외부 단편화 (External fragmentation)](#31-외부-단편화-external-fragmentation)
	- [3.2. 연속 메모리 할당 방식](#32-연속-메모리-할당-방식)
- [5. 페이징 (paging)](#5-페이징-paging)
	- [5.1. 주소 변환(Address Translation)](#51-주소-변환address-translation)
	- [5.2. 내부 단편화(Internal Fragment)](#52-내부-단편화internal-fragment)
	- [5.3. 페이지 테이블 만들기](#53-페이지-테이블-만들기)
	- [5.4 보호와 공유](#54-보호와-공유)
- [6. 세그멘테이션 (Segmentation)](#6-세그멘테이션-segmentation)
	- [6.1. 주소변환 (Address Translation)](#61-주소변환-address-translation)
	- [6.2. 보호와 공유](#62-보호와-공유)
	- [6.3. 세그멘테이션 vs 페이징](#63-세그멘테이션-vs-페이징)

<!-- /TOC -->

## 1. 메모리 역사

 과거에는 메모리가 매우 비싼 자원으로 용량이 작았기 때문에, 운영체제에서 메모리에 대한 관리가 매우 중요했다.

- 메모리의역사
  - Core memory
  - 진공관 메모리
  - 트랜지스터 메모리
  - 집적회로 메모리: SRAM, DRAM
- 메모리 용량
  - 1970년대: 8-bit PC 64KB
  - 1980년: 16-bit IBM-PC 640KB => 1MB => 4MB
  - 1990년: 수MB => 수십 MB
  - 2000년~: 수백 MB => 수 GB

- 프로그램 변천
  - 기계어/어셈블리어
  - C언어
  - 자바, 객체지향형 언어
  - 숫자 처리 => 문자 처리 => 멀티미디어 처리 => Big data
  - 메모리 용량이 증가해도, 프로그램 크기 또한 증가하기 때문에 메모리의 크기는 언제나 부족하다.
    - 메모리의 낭비를 없애는 방법이 중요하다
    - 가상 메모리(virtual memory)

## 2. 프로그램을 메모리에 올리기

![image](https://user-images.githubusercontent.com/53181778/77520212-c5177080-6e78-11ea-84c5-b7a7f45d7fdf.png)

- 메모리는 주소(address)와 데이터(data)로 구성되어 있다.

  - 각 주소에 데이터가 저장됨

- CPU는 메모리에 address bus를 통해 접근하고, 메모리와 CPU는 데이터를 data bus로 주고 받는다.

  - address bus는 단방향 : CPU → Memory
  - data bus는 양방향 : CPU ↔ Memory

- 프로그램 빌드는 소스 파일, 목적 파일, 실행 파일 순으로 생성 된다.

  - Source file(원천 파일) : 고수준 언어 또는 어셈블리어

  - Object file(목적 파일) : 컴파일 또는 어셈블 결과 (`.o`)

  - Excute file(실행 파일) : 링크 결과

    ![image](https://user-images.githubusercontent.com/53181778/77527978-09107280-6e85-11ea-8438-242bf9f85e83.png)

  - 컴파일 : 컴파일러에 의해 고수준 언어로 작성된 소스파일을 목적파일(기계어)로 변환해 주는 작업
  - 어셈블 : 어셈블러에 의해 어셈블리어로 작성된 파일을 기계어(목적파일)로 변환해 주는 작업
  - 링크 : 링커에 의해 목적파일들과 라이브러리를 링크 시켜 실행파일을 만들어 주는 작업

- 프로그램은 `code`, `data`, `stack` 영역으로 나누어져 있다. 기본적으로 프로그램은 code와 data로 구성 되어있고, 운영체제에 의해 프로그램이 메모리 상으로 올려지면 code와 data영역 이외에 stack 영역을 할당 받게 된다. stack 영역은 지역변수와 함수 호출에 사용된다.

- 실행파일을 메모리에 올리기 위해 운영체제는 프로그램의 메모리 주소를 정해주게 된다.

- 다중 프로그래밍 환경에서는 여러 프로그램이 메모리에 올라가고 내려가고를 반복하기 때문에, 한 프로그램은 고정적인 공간을 사용할 수 없다. 즉, 프로그램이 메모리에 할당될 때 마다 다른 주소공간을 사용하기 때문에 가 별도로 존재한다. 이러한 사항을 해결해주기 위해 `MMU`를 사용한다. MMU내 부에는 `재배치 레지스터(Reloctaion register)`가 존재하는데, 재배치 레지스터를 사용해서 프로그램이 어느 주소를 사용하더라도 실제 메인 메모리에 할당된 주소에 접근 할 수 있도록 **address translation** 동작을 수행한다.

  > 이전에 배웠던 `MMU`(Memory Management Unit)는 메모리 보호를 위해 사용되었다.  `base`와 `limit` 레지스터가 있어 CPU에서 주소에 접근 할 때 해당 주소가 프로그램의 base나 limit 범위를 벗어나면 인터럽트가 발생하여 그 프로그램을 강제로 종료시킨다.

  ![image](https://user-images.githubusercontent.com/53181778/77528951-bc2d9b80-6e86-11ea-8a02-50425011337a.png)

  - 프로그램은 메인 메모리에 해당 주소를 사용할 수 있는지 여부를 생각하지 않고 주소를 사용한다. 해당 프로그램이 사용하는 시작 주소가 0번지라고 할 때, 실제 메인 메모리에서는 할당되는 주소가 유동적이기 때문에 0번지라는 주소를 실제 할당된 주소로 변경해주어야 한다. 이때 재배치 레지스터를 이용한다.

    만약, 프로그램이 메인 메모리 500번지에 할당되어 재배치 레지스터값이 500으로 설정되었다면, CPU에서 프로그램의 0번지를 사용할 때 MMU를 통과하면 재배치 레지스터에 의해 500번지로 변경된다. 그 결과 CPU는 0번지를 사용하는 것으로 알고 있지만, 실제 메모리에서는 MMU에 의해 500번지를 사용하고 있는 것이다.

    CPU에서 다음 접근할 주소를 메모리에서 받을 때 10번지를 받았다면, CPU는 10번지에 접근하지만, MMU의 재배치 레지스터에 의해 실제로는 510번지에 접근하게 된다. (offset : 500)

    즉 , 프로그램의 실제 메모리 주소 공간의 위치를 CPU가 모르더라도 프로그램의 실행에 전혀 문제가 없게 된다.

- 논리 주소와 물리 주소

  MMU에 의해 아래와 같이 주소는 두 가지로 구분된다. CPU에서 사용하는 주소는 **논리 주소(logical address)**라고 하고, 메모리가 사용하는 주소는 **물리 주소(physical address)**라고 한다.

  ![image](https://user-images.githubusercontent.com/53181778/77531071-41667f80-6e8a-11ea-93a1-cf7cc35573bc.png)



## 3. 메모리 낭비 방지

메모리를 효율적으로 사용하기 위해 운영체제는 메모리를 관리한다.

### 3.1. 동적 적재 (Dynamic Loading)

- 프로그램 실행에 반드시 필요한 `루틴/데이터`만 적재하여 메모리 낭비를 줄이는 방법으로, 어떤 부분이 실제 필요한 상황이 되었을 때 해당 부분을 메모리에 올려준다.

  - 프로그램 내의 모든 루틴이 다 사용되는 것이 아니다.

    ex) 오류 처리 : 대부분의 상황에서는 일어나지 않음 → 실제 오류가 발생할 경우 올려주면 된다.

  - 모든 데이터(data)가 다 사용되는 것은 아니다.

    ex) 배열

  - 모든 클래스가 다 사용되는 것은 아니다.

    ex) 자바

> cf) 반대로, 모든 루틴과 데이터를 적재하는 것을 정적 적재(static loading)이라고 한다. 현대 운영체제는 대부분 동적 적재를 사용한다.

### 3.2. 동적 연결 (Dynamic Linking)

- 여러 프로그램에 공통 사용되는 라이브러리

  - 공통 라이브러리 루틴(Library routine)을 메모리에 중복으로 올리는 것은 낭비

  - 라이브러리가 메모리에 바로 적재되는 것을 방지하기 위해, 메모리에 적재 된 후 라이브러리의 링크 작업을 수행한다. 이미 메모리에 적재된 동일한 라이브러리가 있다면, 해당 라이브러리를 메모리에 또 적재하지 않고, 기존에 적재된 라이브러리와 링크된다.
    즉, 오직 하나의 라이브러리 당 하나의 라이브러리 루틴만 메모리에 적재되고, 다른 애플리케이션 실행 시 이 루틴과 연결(link)된다.

    - cf) 정적 연결(static linking) : 처음 부터 라이브러리를 연결하고 모두 메모리에 적재하는 것

  - 이러한 라이브러리를 리눅스에서는 `공유 라이브러리` (Shared library)라 하고,  윈도우에서는 `동적 연결 라이브러리`(Dynamic Linking library : DDL) 이라 한다.

    > 윈도우에서 확장자가 `.DLL`로 되어 있다.
    >
    > 리눅스에서는 확장자가 `.so`로 되어있다. (shared object)

- 예시

  아래의 프로그램1과 프로그램2가 공통으로 `printf`를 사용하고 있다. 두개를 동시에 적재하면 메모리 낭비이기 때문에 하나의 printf를 메모리에 올려 같이 사용하게 된다.

  - 프로그램 1

    ```c
    // P1
    int a = 1;
    int b = 2;
    printf("%d\n", a + b);
    ```

  - 프로그램 2

    ```c
    // P2
    int a = 1;
    int b = 2;
    printf("%d\n", a * b);
    ```

    ![image](https://user-images.githubusercontent.com/53181778/77532895-b38c9380-6e8d-11ea-994e-a87db62eb51d.png)

### 3.3. Swapping

- 메모리에 적재되어 있으나 현재 사용되지 않고 있는 프로세스를 확인하여 메모리에서 내린다.
- 프로세스를 이미지 형태로 만든 후 하드디스크에 위치한 Backing store (= swap device)에 임시 저장다. 메모리에서 Backing store로 가는 것을 **swap-out**, 다시 Backing store에서 메모리로 가는 것을 **swap-in**이라고 한다.

- 프로세스 이미지는 해당 프로그램이 메모리에 적재된 후 실행되면서 데이터를 추가하거나 변경하는 등의 과정을 거쳤기 때문에, 현재 실행중인 데이터의 상태를 가진 프로세스 파일을 이미지라고 부른다.

  > 이미지는 하드디스크에 존재하는 프로그램(실행파일)과는 전혀 다르기 때문에  따로 저장해야한다.

  > swapping 과정으로 인한 프로세스 이미지를 저장하기 위해 하드디스크의 일부분을 분리하여 사용 ( **backing store** 또는 **swap device**)

- Backing store의 크기는 대략 메인 메모리 크기 정도로 예상할 수 있다. 메모리의 모든 프로세스가 쫓겨난다고 해도 메인 메모리 크기를 넘지 않기 때문이다. 메인 메모리 크기가 크지 않은 PC나 스마트폰은 하드디스크의 일부를 backing store로 사용하지만, 메모리 크기가 크다면 따로 하드디스크 자체를 backing store로 사용하는 경우도 있다.

- Swap-out된 프로세스는 다시 swap-in을 할 때, 이전의 메모리 주소 공간이 아닌 `새로운 주소 공간`으로 갈 수도 있다. 이는 해당 프로세스가 backing store에 있는 동안 다른 프로세스가 해당 주소 공간을 사용할 수 있기 때문에다. 하지만 이는 `MMU의 재배치 레지스터`로 인해 어디에 적재되는지 상관없이 정상적으로 수행할 수 있다.

- 현재는 프로세스의 크기가 커지고, 하드디스크는 메인 메모리보다 속도면에서 매우 느리므로 swapping 동작의 오버헤드는 크다고 볼 수 있지만 이로 인해 얻는 이득이 더 많으므로 대부분 운영체제는 이를 사용하고 있고, 속도가 중요한 서버 컴퓨터나 슈퍼 컴퓨터는 backing store를 하드디스크가 아닌 좀 더 빠른 저장 장치를 사용하기도 한다.

## 4. 연속 메모리 할당 (Contiguous Memory Allocation)

과거와 달리 현재는 메모리에 여러 프로세스가 할당되는 다중 프로그래밍 환경이다.

![image](https://user-images.githubusercontent.com/53181778/77614136-5ee82780-6f24-11ea-8769-0e7f8f973572.png)

- 부팅 직후인 메모리의 초기 상태는 OS만 메모리에 올라가 있는 형태로, 하 나의 커다란 hole(Big single hole)이 존재한다.

- 프로세스가 메모리에  순차적으로 할당되지만, 여러 프로세스의 생성과 종료가 반복되면서, 중간에 구멍들(scattered holes)이 생긴다.

### 3.1. 외부 단편화 (External fragmentation)

hole들을 합치면 어떤 큰 프로세스를 올릴 공간이 되지만, hole 개별 공간에는 큰 프로세스는 hole에 넣을 수 없다. 이것을 `외부 단편화(External fragmentation)`라 한다.

> 예) hole이 3개가 있고 각 크기는 50byte, 50byte, 80byte이다. 그런데 할당하려는 프로세스의 크기는 150byte이다. 각 hole들을 하나로 합치면 230byte로 이 프로세스를 할당할 수 있는데 실제로는 hole들이 분리되어 있으므로 프로세스가 할당되지 못한다.

### 3.2. 연속 메모리 할당 방식

- 외부 단편화를 최소화 하기 위해 연속 메모리를 할당 방식을 사용한다. 3가지의 방식이 있다.
  1.  First-fit (최초 적합)
  2. Best-fit (최적 적합)
  3. Worst-fit (최악 적합)

아래의 예시를 살펴보면서 차이점을 확인해 보자.

> Hole 5개 :  100KB, 500KB, 600KB, 300KB, 200KB
>
> 프로세스 4개 : P1, P2, P3, P4 (212KB, 417KB, 112KB, 426KB)

- first-fit (최초 적합)

  최초 적합은 할당할 프로세스 크기보다 크거나 같은 hole을 탐색하는 순서 중에서 가장 먼저 찾은 hole에 프로세스를 할당하는 방법

  ![image](https://user-images.githubusercontent.com/53181778/77614811-c0f55c80-6f25-11ea-91c7-df8f8841e821.png)

- Best-fit (최적 적합)

  최적 적합은 할당할 프로세스 크기 보다 큰 hole 중에서 프로세스의 크기와 `차이가 가장 작은 hole`에 프로세스를 할당하는 것이다.(hole크기는 프로세스 크기보다 반드시 커야 한다.)

  ![image](https://user-images.githubusercontent.com/53181778/77614939-10d42380-6f26-11ea-85d7-81d9f8a2b40f.png)

- Worst-fit (최악 적합)

  최적 적합과 반대로, 할당할 프로세스 크기와 hole 크기의 차이가 가장 큰 hole에 프로세스를 할당하는 것이다.

  ![image](https://user-images.githubusercontent.com/53181778/77614985-2b0e0180-6f26-11ea-9bfa-0a059ba28d15.png)

- 각 할당 방식의 성능

  - 속도 : first-fit이 가장 빠르다.
  - 메모리 이용률면에서는 best-fit가 가장 빠르고, first-fit가 평균적인 성능을 보여준다.
  - `best-fit`를 사용하더라도 외부 단편화로 인해 **전체 메모리의 1/3 정도를 낭비**한다고 한다. 이는 메모리가 심각하게 낭비되는 것이다.

  > 이를 해결하는 방법 중 하나는 **Compaction** 이다. compaction은 여러 곳에 흩어져있는 hole들을 강제로 하나로 합치는 것이다. 하지만 hole을 옮기는 오버헤드가 너무 크고, 어느 hole을 옮겨야 빠르게 합칠 수 있는지에 대한 최적 알고리즘이 존재하지 않는 큰 단점이 존재한다.

## 5. 페이징 (paging)

- 연속 메모리 할당방식이 메모리 낭비를 심하게 하는 것을 확인 할 수 있었고, Compaction은 오버헤드가 너무 큰 방식이다. `페이징` 기법은 프로세스의 메모리를 연속으로 할당하는 것이 아니라, 프로세스를 쪼개서 메모리의 빈 공간의 주소에 할당하여 `외부 단편화`를 해결한다.

- 프로그램 뿐만 아니라 메모리 hole도 일정한 단위로 쪼개어 작은 조각으로 만든다.  만약 50byte 크기의 프로세스가 있다고 하고, 페이징의 크기는 각 10byte로 나누면 5개의 조각으로 쪼개지고, 메모리 또한 10byte씩 쪼개져야 한다.

- 프로세스를 나눈 조각을 **page** 라 하고, 메모리를 나눈 조각을 **frame** 이라 한다.

- 하지만, 메모리에 올라간 프로세스의 주소가 연속적이지 않고 여기저기 퍼져있는 상황이 되기 때문에 제대로 실행하기 위해서는 별도의 작업이 필요하다.

  ![image](https://user-images.githubusercontent.com/53181778/77616597-ee440980-6f29-11ea-85d9-08038e6f1277.png)

- 위 그림과 같이 프로세스 P1을 5개의 페이지로 나누고, 이를 메인 메모리 5곳에 나눠서 할당한다. CPU는 논리 주소로 프로그램이 설정한대로 연속적인 주소값으로 명령을 내리지만, 이는 메모리에 접근하기 전에 각 페이지의 실제 메모리 주소가 저장되어 있는 **`테이블`에서 물리 주소로 변경된다.**

  `프로세스`는 `페이지의 집합`이고, `메모리`는 `프레임의 집합`이다. 프로세스를 정상적으로 사용하기 위해 **MMU의 재배치 레지스터를 여러개 사용**해서 위의 그림과 같이 각 페이지의 물리 주소로 변경해준다. 이러한 `여러 개의 재배치 레지스터`를 활용한 MMU가 **페이지 테이블(Page Table)** 이 된다.

### 5.1. 주소 변환(Address Translation)

페이징 기법을 사용하기 위해서는 여러 개로 흩어진 페이지에 접근하기 위해서 페이지 테이블을 통해 주소를 변환해야 한다.

- **논리 주소(Logical address)**

  - CPU가 `내는 주소`(CPU가 알고있는 프로세스의 주소)는 2진수로 표현되고 전체 m비트가 있다고 가정

  - 하위 n비트는 오프셋(offset) 또는 변위(displacement)라 함

    - 페이지의 크기가 16byte면, n은 4bit를 사용

  - 그리고 상위 **m-n 비트는 페이지의 번호**에 해당(n = d, m - n = p)

    ![image](https://user-images.githubusercontent.com/53181778/77618353-1170b800-6f2e-11ea-9038-7d1400ee6001.png)

- **주소 변환** : 논리 주소 → 물리 주소 (Physical address)

  - 페이지 번호(p)는 페이지 테이블 인덱스 값
  - p에 해당되는 프레임 번호(f)로 매칭되어 변환
  - 변위(d)는 변하지 않음

- 예시
  - Page size = 16bytes
  - Page Table: 5, 3, 2, 8, 1, 4
  - 논리 주소 50번지는 물리주소 몇 번지인가?

  ![image](https://user-images.githubusercontent.com/53181778/77618551-71675e80-6f2e-11ea-9801-604a6fe50ce8.png)

  위 그림은 프로세스 P가 메모리에 할당된 모습이다. CPU가 50번지에 접근하려고 한다. 그러면 페이지 테이블의 정보를 읽기 위해 논리 주소를 `p`와 `d`값으로 나눠야 한다.

   p, d를 계산해보면, 현재 논리 주소는 50이며, 이진수로 나타내면 `110010`이다. 먼저 페이지의 크기가 16byte 이기 때문에 d는 4bit이다. 즉, `110010`의 뒤에서 4칸이 d이다. p는 d를 제외한 나머지 2칸이 된다.

  > 50 = 110010
  > p = 11
  > d = 0010

  p(페이지)는 이진수로 `11`이고, 십진수로 `3`이다. 즉, 페이지 테이블의 3인덱스를 가리킨고 페이지 3번에 해당하는 프레임 번호는 `8번`이므로, 물리주소를 구성하는 f(프레임)값은 페이지 테이블에 의해 `8`이 된다.

  > f = 1000
  > d = 0010
  > 물리주소 = 10000010

  `물리주소는 f와 d로 구성`되어 있으므로 물리주소는 **이진수로 `10000010` 이 되고, 십진수로 `130번지` ( = 128 + 2) **가 된다.

  > 즉, 8번째 프레임의 시작주소는 128번지(2<sup>7</sup>)가 되고, 프레임 내부에서 2의 변위를 가지게 되므로 128+2 = 130이 된다.

  연속 메모리 할당을 하면서 외부 단편화가 발생하여 이를 해결하기 위해 페이징 기법을 사용했지만, 하지만 페이징은 외부 단편화가 아닌 **내부 단편화**가 발생한다.

### 5.2. 내부 단편화(Internal Fragment)

내부단편화는 프로세스 크기가 페이지 크기의 배수가 아닐 경우, 마지막 페이지는 한 프레임을 다 채우지 않는다. 즉, 이로 인해 다른 프로세스에서 다 채워지지 않은 프레임의 공간을 사용하지 못하는데, 이는 결국 `메모리 낭비`로 이어진다.

예를 들어, 13bytes 크기의 프로세스 P가 있고, 페이지 크기( = 프레임 크기)는 4bytes로 P를 페이지로 나누면 각가 **4, 4, 4, 1**byte 의 페이지가 만들어진다. 여기서 마지막 1bytes 페이지는 프레임 크기 보다 3byte작다. 즉, 프레임의 3byte는 비어 있게 되고 다른 프로세스에서도 쓰지 못하는 메모리 낭비가 된다.

내부단편화는 해결할 방법이 없지만 내부단편화는 외부단편화에 비해 낭비되는 메모리 공간이 매우 적다. 내부단편화의 **최대 낭비되는 크기는 프로세스 당 page size - 1** 이 된다. 외부 단편화는 평균적으로 최대 전체 메모리의 1/3이 낭비되기 때문에, 내부 단편화가 외부 단편화보다는 좋은 효율을 가지게 된다.

낭비되는 공간을 줄이기 위해서는 페이지 사이즈를 작게 하면 되지만, 그 만큼의 오버헤드가 발생하게 되어 적절한 페이지 사이즈를 설정하는 것이 중요하다.

### 5.3. 페이지 테이블 만들기

페이지 테이블을 만드는 방법은 여러가지 방법이 있다.

1. CPU 내부의 레지스터를 이용
   - 주소 변환 속도는 빠르지만, CPU 내부에서 사용할 수 있는 레지스터는 한정되어 있기 때문에 페이지 테이블의 크기가 제한됨
2. 메인 메모리를 이용
   - 메모리 내부에 만드는 것의 장단점은 CPU와 반대이다. 즉, 장점은 페이지 테이블의 크기에 제한에 자유로운 것이고, 단점은 주소 변환 속도가 느리다는 것이고, CPU는 프로세스의 주소에 접근하기 위해서 메모리에 위치한 페이지 테이블에 한 번, 실제 주소로 접근하는데 한 번 접근하여, **메모리에 총 2번**접근 하게 됨
3. **TLB (Translation Look-aside Buffer)**
   - 실제로 사용하는 방식으로   캐쉬메모리(SRAM)을 이용해서 만드는 방식을 이용한다. 하지만, 캐쉬메모리와 목적이 다르기 때문에 `TLB`라고 부르고, CPU보다 변환 속도는 느리고 메모리보다 테이블 크기는 작지만, CPU보다 테이블 크기가 크고 메모리보다 변환 속도가 빠르다.
   - 이는, 캐시와 동작방식이 비슷하다. 실제 페이지 테이블은 메모리에 존재하고, 그 중 일부만 TLB에 올리게 된다. 만약, TLB에 유요한 페이지가 올라와 있지않으면 캐시 미스가 발생하여 메모리에 접근하여 페이지 테이블의 해당부분을 다시 로드한다.

- TLB 성능 평가

  - EMAT (Effective Memory Access Time) = 메모리에 접근하는데 걸리는 시간

    - `EMAT = h(Tb + Tm) + (1 - h)(Tb + Tm + Tm)` , (h는 hit ratio)
    - `Tm`(메모리를 읽는 시간) = 100ns
    - `Tb`(TLB를 읽는 시간) = 20ns
    - `hit ratio`(TLB에 유요한 페이지 엔트리가 있을 확률) = 80%

    - EMAT = 0.8 * (20 + 100) + 0.2 * (20 + 100 + 100) = 140ns
      - 40%의 손실이 있긴하지만, 메모리를 사용한다면 200ns가 소요되기 때문에 보다 효율적이다. 그리고 실제 `ht ratio`는 95% 이상이기 때문에 보다 효육적으로 동작한다고 볼 수 있다.

  - hit ratio는 `테이블 엔트리 개수`와 연관이 있다.

### 5.4 보호와 공유

- 보호 (Protection): 해킹 등 방지

  - 모든 주소는 페이지 테이블을 경유하므로, 페이지 테이블 엔트리마다 r, w, x 비트 두어 해당 페이지에 대한 접근 제어

    > r : read
    >
    > w : write
    >
    > e : excute

  - 해당 작업의 권한이 없는 요청이 생기면 프로세스를 강제종료 시키게 된다. 예를들어 아래 그림에서, 1번 페이지 엔트리처럼 쓰기 비트가 꺼져있는 페이지에 쓰기 작업을 시도하면 CPU에 인터럽트가 발생하여 `ISR에서 강제로 해당 프로세스를 종료`시킨다.

  ![image](https://user-images.githubusercontent.com/53181778/77726999-3417d500-6ff1-11ea-979a-b922b56a39dd.png)

- 공유 (Sharing): 메모리 낭비 방지
  - 같은 프로그램을 쓰는 복수 개의 프로세스가 있다면,  `non-self- modifying code` (= reentrant code = pure code)인 경우라면, `Code + data + stack` 영역 중에 `code 영역은 공유 가능`

    > non-self- modifying code : code가 변하지 않는 코드
    >
    > reentrant  code : 재진입 가능 코드

  - 프로세스의 페이지 테이블에서 같은 코드 영역을 가리키게 한다.

## 6. 세그멘테이션 (Segmentation)

페이징은 프로세스를 `일정한 물리적 크기`로 나눠서 메모리에 할당하였다. 반면에 세그먼테이션은 프로세스를 **논리적 내용을 기반**으로 나눠서 메모리에 배치하는 것을 말한다.

세그먼테이션은 프로세스를 세그먼트(segment)의 집합으로 만들고, 각 세그먼트의 크기는 일반적으로 같지 않다. 프로세스를 `code + data + stack` 으로 나누는 것 역시 세그먼테이션의 모습이다. 물론 code, data, stack 각각 내부에서 `더 작은 세그먼트`로 나눌 수도 있다.

세그먼트를 메모리에 할당할 때는 페이지를 할당하는 것과 동일하다. 하지만 다른 MMU를 사용하는데, 세그먼테이션을 위한 테이블은 **세그먼트 테이블**이라고한다. 세그먼트 테이블은 `세그먼트 번호와 시작 주소(base), 세그먼트 크기(limit)`를 엔트리로 가진다.

세그먼트에서 주소변환은 페이징과 유사하다. 차이점은 세그먼트의 크기는 일정하지 않기 때문에, 테이블에 **limit** 정보가 주어지고 CPU에서 해당 세그먼트의 크기를 넘어서는 주소가 들어오면 인터럽트가 발생하여 해당 프로세스를 강제로 종료시킨다.

### 6.1. 주소변환 (Address Translation)

- 페이징의 페이지(p) 대신 세그멘테이션에서는 세그먼트(s)사용(이름만 다르고 비슷한 개념)

![image](https://user-images.githubusercontent.com/53181778/77730042-ea7eb880-6ff7-11ea-90fb-3ae9aa897b64.png)

- 위 그램은 세그먼트 테이블과 프로세스가 할당된 메모리의 모습이다. 페이징 주소 변환과 동일하게 `d`는 논리주소와 물리주소가 동일하고, a = base[s]이다. 즉, 물리주소는 base[s] + d가 된다. 이때, d가 limit 보다 크게되면 범위를 벗어나기 때문에 `segment violation`으로 강제종료된다.

  > 논리 주소 s =2, d = 100 :물리주소 4400번지
  >
  > 논리 주소 s =1, d = 500 : 강제종료

### 6.2. 보호와 공유

- 보호 (Protection) : 해킹 등 방지
  - 모든 주소는 세그멘트 테이블을 경유하므로, 세그멘트 테이블 엔트리마다 r, w, x 비트 두어 해당 세그멘트에 대한 접근 제어 가능
  - 세그멘테이션은 코드,데이터,스택 영역이 확실하게 구분되어 있어 권한을 관리하기 좋아 페이징보다 효율적이다.

- 공유 (Sharing): 메모리 낭비 방지
  - 같은 프로그램을 쓰는 복수 개의 프로세스가 있다면, Code + data + stack 에서 code 는 공유 가능 (단, non-self- modifying code = reentrant code = pure code 인 경우)
  - 프로세스의 `세그멘트 테이블 코드 영역`이 같은 곳을 가리키게 한다.
  - 공유도 마찬가지로, 코드영역이 확실하게 구분되어 있기때문에 페이징보다 세그멘테이션이 더 효율적이다.

### 6.3. 세그멘테이션 vs 페이징

- 세그멘트 크기는 고정이 아니기 때문에 외부단편화 문제가 해결되지 않음
  - hole의 크기가 일정하지 않기 때문에, 외부단편하 문제 발생
- 세크먼테이션은 보호와 공유에서는 효율적이지만, 공간 활용측면에서 페이징보다 효율이 떨어진다.
- **세그멘테이션과 페이징의 장점을 합친 방법을 사용** : Paged segmentaion
  - 영역을 segment로 나눈 뒤 paging하는 기법이다. 즉, 각각의 code,data,stack 영역을 각각 따로 페이징 하는 것
  -  예시 : Intel 80x86
  - 단점 : 세그먼트와 페이지가 동시에 존재하기 때문에 주소 변환도 두 번해야한다. 즉 CPU에서 나온 논리주소를 세그먼트 테이블에서 주소 변환을 하고, 그 다음 페이지 테이블에서 또 주소 변환을 해야하는 시간적 비용이 든다.
